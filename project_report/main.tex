\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
    % \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2024


% ready for submission
\PassOptionsToPackage{numbers}{natbib}
\usepackage[preprint]{neurips_2024}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{array}
\usepackage{float}
\usepackage{subcaption}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{tabularx, makecell}
\usepackage{booktabs}
\usepackage{multirow}
\newcommand{\instructions}[1]{{\color{blue} #1}}

\title{Final Project For ECE228 Track Number \# 1}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.


\author{%
  Group Number \#15: Harini Gurusankar
  % examples of more authors
  \And
  Girish Krishnan \\
  \AND
  Ryan Irwandy  \\
  \And
  Yash Puneet \\
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}




\begin{document}

\maketitle

\begin{abstract}
    Full-waveform inversion (FWI) retrieves subsurface velocity from multi-source seismic gathers but is notoriously expensive and noise-sensitive.   Within the Kaggle FWI challenge\footnote{Competition link: \url{https://www.kaggle.com/competitions/waveform-inversion}} we benchmark several neural operators on a 2 000-sample \textsc{OpenFWI} subset (5 sources, $1000\times70$ grid).  
    The candidates are Fourier DeepONet, InversionNet, VelocityGAN, residual UNet, 2-D Fourier Neural Operator, three (Augmented) Neural ODEs, and a PCA\,+\,MLP baseline and are trained end-to-end to predict $70\times70$ velocity maps.  
    Fourier DeepONet delivers the lowest mean-absolute error, with VelocityGAN and InversionNet close behind, while Neural-ODE and PCA models lag by roughly an order of magnitude.  
\end{abstract}


%%% BEGIN INSTRUCTIONS %%%


% \section*{Submission guideline: Please remove THIS section and all the \textcolor{blue}{blue} instructions from your final submission}
% \subsection*{Submission guideline}
% \begin{itemize}
%     \item Please mention the track number at title (\textbf{Track 1}: Reproducing an existing machine learning + physical / engineering / science application paper and implement improvement ideas on top ot it; \textbf{Track 2}: Open-ended project. 
%     \item Please enter the \textbf{Group Number \#} before the first name of the team. You can find your group number in this  \href{https://docs.google.com/spreadsheets/d/1WOi940jN9U6ZHX3xf5tDbw3-igv2bbjXg1W5AETX8cI/edit?usp=sharing}{Google sheet}. 
%     \item Maximum page limit is 8-page except the Appendix and Reference.
%     \item For citing related literature, please use \verb+\cite+ and Bibtex file (bib.bib in the current folder) to manage your citations.
%     \item A good report should include the following:
%     \begin{itemize}
%         \item Introduction, Background and Related Works. What task/problem are you targeting? What are the prior works in tackling this problem and what are their  limitations? What is your contribution to this problem?
%         \item What method do you propose to solve the problem (e.g. data collection/processing, model input/output, model architecture design, loss function design, incorporate physics knowledge etc)? What's new in your approach? What are the technical challenges that you tackled? 
%         \item Validate your proposed method with experiments and compare your model with existing baselines. What hyper-parameters/dataset are you using? How does your approach compared to other methods under a fair comparison setup? Did you use a package or write your own code (for some parts)? It is fine if you use a package, though this means other aspects of your project must be more ambitious.
%         \item Summarize your findings from the project. Highlight your contributions and discuss the limitations. Outlook for future work.
%     \end{itemize}
%     \item As you work on your final project, ensure you start early and plan your tasks effectively. Document each section clearly in your report. Good luck!
% \end{itemize}

%%% END INSTRUCTIONS %%%


\section{Introduction}
% \instructions{Introduction [10\%]: provide the background and motivation of the problem, and why it is important. Also, include an overview of your project and a brief summary of contributions (listed in bullet points)} 

Geological waveform inversion is used to image subsurface structures by analyzing how seismic waves propagate through the Earth. Sources like drills generate waves recorded by receivers (Figure~\ref{fig:intro}), from which we estimate the underground velocity map $c(x, z)$. High velocities suggest dense materials, while low velocities may indicate voids or softer regions. These maps are crucial for oil exploration, infrastructure planning, and earthquake fault detection.

\vspace{4pt}
The forward process is modeled by the acoustic wave equation:
\[
\nabla^2 p(x, z, t) - \frac{1}{c(x, z)^2} \frac{\partial^2 p(x, z, t)}{\partial t^2} = s(x, z, t)
\]
where $p$ is the seismic wavefield and $s$ is the source. Inversion recovers $c(x, z)$ from observed $p$.

\begin{figure}
    \centering
    \includegraphics[width=0.49\linewidth]{figures/intro1.png}
    \hfill
    \includegraphics[width=0.49\linewidth]{figures/intro2.png}
    \caption{(Left) Surface-seismic acquisition. (Right) High-resolution velocity model inferred from recorded data.}
    \label{fig:intro}
\end{figure}

While underground receivers offer accurate data, they are costly and disruptive. Surface receivers are cheaper but introduce significant noise. Our work explores learning-based approaches to infer velocity maps from surface seismic data using various neural architectures.

We evaluate several models, including Fourier DeepONet, Residual UNet, InversionNet, VelocityGAN, 2D Fourier Neural Operator, Augmented Neural ODEs, and a PCA-based MLP. Fourier DeepONet achieved the best mean absolute error on our testing set, placing us \textbf{591st of 6446 entrants} in the Kaggle competition.

\paragraph{Contributions.}
Brief summary of our contributions (see Appendix for full breakdown):

\begin{itemize}[leftmargin=1.2em, itemsep=0.4em]
    \item \textbf{Fourier DeepONet:} Implemented spectral DeepONet with U-Net decoder; best performance on both datasets; evaluated noise robustness. [Girish]
    \item \textbf{Neural ODEs:} Built MLP and CNN-based Neural ODEs, including augmented variants. [Harini]
    \item \textbf{VelocityGAN \& InversionNet:} Reproduced and trained both baselines. VelocityGAN performed well; InversionNet overfit. [Girish]
    \item \textbf{Residual UNet:} Trained deeper UNet variant with skip connections. [Girish]
    \item \textbf{Fourier Neural Operator:} Adapted 2D FNO; stable but not state-of-the-art. [Yash]
    \item \textbf{PCA + MLP:} Designed a compact baseline combining PCA with MLP. Motivates future PCA-CNN variants. [Ryan]
\end{itemize}

\section{Related work} 
% \instructions{Related works [5\%]: Please review the related work in this area, state the challenges/limitations of the existing methods, and how does your proposed work will help address the prior limitations and/or advance the current state-of-the-art for this problem.}

\textbf{Learning-based FWI.}  
CNN surrogates \textit{InversionNet} and cGAN-based \textit{VelocityGAN}
replace iterative adjoints, giving $10$-$100\times$ speed-ups but suffer from
(i) narrow receptive fields, (ii) poor long-range physics, and (iii) fragility
to noise and domain shift.  
\textit{Fourier DeepONet} (F-DONet)~\cite{fdonet} mitigates (i)-(ii) with
spectral convolutions and branch-trunk conditioning, setting the current
\textsc{OpenFWI} SOTA, yet is compared only to the two baselines above.

\textbf{Operator networks.}
Fourier Neural Operators (FNO)~\cite{fno} provide mesh-independent spectral
layers; Augmented Neural ODEs (ANODE)~\cite{anode} offer continuous-depth
models.  Neither has been evaluated on seismic gathers and both face open
practical issues: GPU memory (FNO) and solver stability (ODEs).

\textbf{Dimensionality reduction.}
Receiver redundancy has motivated statistical preprocessing
(e.g.\ PCA for gas-hydrate analysis~\cite{jones2023waveform}), but its merit
for high-fidelity FWI regression is untested.

We bridge these gaps by (i) benchmarking seven architectures—UNet,
InversionNet, VelocityGAN, F-DONet, \mbox{2-D} FNO, Neural ODE, ANODE, and a
PCA\,+\,MLP baseline—on a common \textsc{OpenFWI} split; (ii) probing their
robustness across depth, velocity, and domain shift (Kaggle test); and
(iii) scaling the best model via distributed training to the full 622 GB
dataset, advancing practical SOTA in learned FWI.

\section{Methodology}
% \instructions{Method/Approach [40\%]: this should be the main section of your report. Describe your approach, any equation and/or algorithm you developed to solve the problem. This part will be evaluated based on both scientific merit and technical depth.} \\

This section describes the different models we implemented along with their training strategies.

\subsection{Fourier DeepONet}

\begin{figure}
    \centering
    \includegraphics[width=0.6\linewidth]{figures/FDONet.png}
    \caption{\textbf{Fourier-DeepONet architecture.} 
    \textbf{(A)} Branch $\mathcal{B}$ and trunk $\mathcal{T}$ networks lift inputs to latent space; merger denotes pointwise multiplication. 
    \textbf{(B)} Fourier layer~\cite{li2020fourier}. 
    \textbf{(C)} U-Fourier block~\cite{wen2022u}. 
    \textbf{(D)} Projection layer $Q$. 
    \textbf{(E)} Feature maps $\mathbf{z}_i$, $i=0,\dots,4$. \emph{Source}:~\cite{fdonet}.}
    \label{fig:fdonet}
\end{figure}

\textbf{Fourier DeepONet (F-DONet)} maps input seismic data \(u\in\mathbb{R}^{5\times1000\times70}\) and dummy parameter \(p\in\mathbb{R}\) to velocity fields \(v\in\mathbb{R}^{70\times70}\). The \emph{branch} net \(\mathcal{B}(u)\in \mathbb{R}^{w\times70\times70}\) and \emph{trunk} net \(\mathcal{T}(p)\in \mathbb{R}^{w\times1\times1}\) are combined via element-wise product with bias to yield \(z_0 = \mathcal{B}(u)\odot \mathcal{T}(p)\).

The decoder applies four stacked U-Fourier blocks followed by projection:
\[
z_i = \text{U-Fourier}(z_{i-1}),\quad \hat{v} = Q(z_4),
\]
where each U-Fourier block performs:
\[
\text{U-Fourier}(z) = \sigma\bigl(\text{FourierConv}(z) + \text{Ublock}(z)\bigr).
\]
Here, \(\text{FourierConv}(z) = \mathcal{F}^{-1}(R_\phi \cdot \mathcal{F}(z))\), with \(\mathcal{F}\) denoting the 2D FFT. 

F-DONet thus combines latent conditioning with multiscale spectral processing for efficient operator learning. See Figure~\ref{fig:fdonet} for an overview.


\subsection{InversionNet and VelocityGAN}

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.48\linewidth}
      \includegraphics[width=\linewidth]{figures/InversionNet.png}
      \caption{InversionNet encoder-decoder.}
      \label{fig:inversionnet_sub}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\linewidth}
      \includegraphics[width=\linewidth]{figures/VelocityGAN.png}
      \caption{VelocityGAN architecture.}
      \label{fig:velocitygan_sub}
    \end{subfigure}
    \caption{\textbf{(a)} InversionNet: 3D seismic input \((B,5,1000,70)\) is compressed via conv layers and decoded into a Tanh-activated \(70\times70\) velocity map. 
    \textbf{(b)} VelocityGAN: InversionNet serves as generator \(G\), paired with patch-wise CNN discriminator \(D\).}
    \label{fig:inversion_velocitygan}
\end{figure}

\textbf{InversionNet}~\cite{inversionnet} is a CNN-based encoder-decoder that maps seismic inputs to velocity maps (Fig.~\ref{fig:inversionnet_sub}). The encoder compresses the \(5\times1000\times70\) input into a latent code, which the decoder upsamples to a \(70\times70\) output using Tanh to match the normalized velocity range.

\textbf{VelocityGAN}~\cite{velocitygan} extends InversionNet by using it as a generator \(G\) in a conditional GAN framework (Fig.~\ref{fig:velocitygan_sub}). A discriminator \(D\) assigns patch-wise real/fake scores. The generator minimizes:
\[
\mathcal{L}_G = \mathrm{BCE}(D(G(s)),\,\mathbf{1}) + \lambda \lVert G(s) - v \rVert_1,
\]
where \(\lambda=100\) weights the \(L_1\) loss. The discriminator loss is:
\[
\mathcal{L}_D = \tfrac{1}{2}\bigl[\mathrm{BCE}(D(v),\,\mathbf{1}) + \mathrm{BCE}(D(G(s)),\,\mathbf{0})\bigr].
\]
This setup balances adversarial training with pixel-wise fidelity, encouraging realistic velocity map generation.

\subsection{Residual UNet}

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{figures/ResidualUNet.png}
    \caption{Residual UNet architecture for seismic-to-velocity inversion. The network uses an encoder to compress the input seismic cube into latent features and a decoder with symmetric up-sampling paths that leverage skip connections. Residual blocks ensure stable gradient flow and enable training of deeper architectures.}
    \label{fig:residual_unet}
\end{figure}

Residual UNet adapts the widely used U-Net~\cite{ronneberger2015u} by integrating residual connections from ResNet~\cite{he2016deep} into each convolutional block. As shown in Figure~\ref{fig:residual_unet}, the network comprises a down-sampling path that applies multiple \emph{ResidualDoubleConv} modules to encode the 5×1000×70 seismic input into a lower-dimensional latent representation. In the up-sampling path, each decoder block receives concatenated features from its encoder counterpart via skip connections, followed by residual up-convolution to reconstruct a 70×70 velocity map.

Formally, each residual block computes: $\mathbf{y} = \sigma\bigl(\mathrm{BN}(W_2 * \sigma(\mathrm{BN}(W_1 * \mathbf{x}))) + \mathcal{S}(\mathbf{x})\bigr)$, where \( * \) denotes convolution, \(\mathrm{BN}\) denotes batch normalization, \(\sigma\) is ReLU, and \(\mathcal{S}\) is either identity or a learned linear shortcut. These shortcuts enable smoother gradient propagation through the network.

\subsection{Neural ODE}
\begin{figure}
    \centering
    \begin{subfigure}[b]{0.47\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/neuralode_structure.png}
        \caption{General structure}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.47\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/augmented_neuralode.png}
        \caption{Augmented MLP base}
    \end{subfigure}
    \caption{Augmented Neural ODE architectures. (a) shows the general structure, where input seismic data is encoded, augmented, solved via ODE integration, and decoded to produce the velocity map. (b) shows the specific Augmented Neural ODE model using an MLP base function.}
    \label{fig:neuralode-merged}
\end{figure}

A Neural ODE treats depth as continuous.  
A conv-encoder $E$ maps the seismic cube $u\!\in\!\mathbb R^{5\times1000\times70}$ to an
initial latent $z_0\in\mathbb R^{d}$.
Latent evolution is defined by a time-invariant vector field
$f_\theta$ (3-layer MLP) via the ODE: $\dot z(t)=f_\theta\!\bigl(z(t)\bigr),\qquad z(0)=z_0$, integrated with \texttt{odeint} (\texttt{torchdiffeq}).
The terminal state $z(1)$ is decoded by a transposed-conv head
$D:\mathbb R^{d}\!\to\!\mathbb R^{1\times70\times70}$,
yielding $\hat v=D\!\bigl(z(1)\bigr)$
(Fig. \ref{fig:neuralode-merged}a).

\textbf{Augmented variants.}  
Following \citet{anode}, we append one inert
dimension $a$ so that $\tilde z=(z,a)$ and integrate
$\dot{\tilde z}=(f_\theta(\tilde z),0)$.
We consider two choices for $f_\theta$:
(i) the same MLP (Fig. \ref{fig:neuralode-merged}b) and
(ii) a shallow CNN, giving three ODE models in total.

\subsection{2-Dimensional Fourier Neural Operator}

To directly learn the space-to-space map
$u\!\mapsto\!v$ we adapt the Fourier Neural Operator \cite{fno}
to 2-D seismic gathers (time $\times$ receiver).
A conv-encoder first compresses $u$ to a $70\!\times\!70\!\times\!c$ feature grid, where $c$ is the number of channels (a hyperparameter).
After concatenating a positional grid
$g\!\subset\![0,1]^2$ (step $0.2$),
the tensor passes through $L=4$
spectral blocks (Fig.\ref{fig:fno-2d}):

\[
\mathrm{Spectral}(x)=
\mathcal F^{-1}\!\bigl(
  W_{\!\text{spec}}\!\cdot\!\mathcal F(x)
\bigr)+W_{\!\text{local}}*x,
\]

where $\mathcal F$ is the 2-D FFT, 
$W_{\!\text{spec}}$ keeps the lowest 32\,modes,
and the second term is a $1\times1$ convolution (skip connection).
A linear projection converts the final feature map to
$\hat v\in\mathbb R^{1\times70\times70}$.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.6\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/FNO2D.png}
        \caption{2D Fourier Neural Operator}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/spectralconv2d.png}
        \caption{Spectral Convolution Block}
    \end{subfigure}
    \caption{(a) Full 2D Fourier Neural Operator architecture used in our experiments. (b) Internal schematic of the spectral convolution block.}
    \label{fig:fno-2d}
\end{figure}

\subsection{Principal Component Analysis (PCA) along with MLP} 

We form a lightweight baseline by reducing the receiver-axis with
Principal Component Analysis (PCA).
For each shot $u\!\in\!\mathbb R^{5\times1000\times70}$ we stack sources
into a $5000\times70$ matrix, apply z-score normalisation,
and project onto the top $k=18$ components
($\!\approx\!95\%$ variance).
Flattening yields a vector
$x\in\mathbb R^{5000\times k}$ that feeds a
four-layer MLP with
LayerNorm\,$\to$\,ReLU\,$\to$\,Dropout.
The network outputs $\hat v\in\mathbb R^{1\times70\times70}$
after a final reshape (Fig.\ref{fig:pca}).
This model tests how far linear dimensionality reduction can go
before spatial structure must be learned end-to-end.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.4\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/PCA1.png}
        \caption{PCA Data Preparation Pipeline.}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.4\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/PCA2.png}
        \caption{PCA-MLP Architecture.}
    \end{subfigure}
    \caption{(a) Seismic waveform data reshaped and reduced via PCA. (b) MLP model applied to PCA-transformed data.}
    \label{fig:pca}
\end{figure}

\section{Experiments}
% \instructions{Results [30\%]: present your results and provide sufficient discussions of the results. 1) Describe what dataset is being used, details in data processing, train-test data split, and hyperparameter choices in your model etc. Provide the sufficient details such that if a reader would like to reproduce your results, they have enough information to do it. 2) Include figures and/or tables showing the quantitative and qualitative performance of your method; 3) Comparison to necessary baseline methods and comparison to your proposed method.} 

\subsection{Dataset and Data Processing}\label{subsec:data}
\textsc{OpenFWI} is a public, 622\,GB benchmark that gathers multi\-fold synthetic seismic-to-velocity pairs generated with finite-difference forward modelling over a variety of 2-D geological scenarios (e.g.\ \emph{FlatVel}, \emph{CurveVel}, \emph{FlatFault}, \emph{CurveFault}, \emph{Style}) \cite{openfwi2021,openfwi2023}.  Each sample consists of a tensor of raw pressure gathers $\mathbf{s}\!\in\!\mathbb{R}^{5\times1000\times70}$ (five sources, 1000 time steps, 70 receivers) and its corresponding velocity map $v\!\in\!\mathbb{R}^{1\times70\times70}$.  
For rapid prototyping we curate a \emph{small subset} composed of one 500-sample batch from the categories \texttt{CurveFault\_A}, \texttt{CurveVel\_A}, \texttt{FlatFault\_A}, and \texttt{Style\_A} (2 000 samples in total).  
After min-max normalization of velocity ($1500$-$4500$\,m/s) and $\log$-amplitude scaling of gathers, the subset is randomly divided 70\% / 20\% / 10\% into training, validation, and test partitions.  
The best architecture found on this subset is subsequently trained on the \emph{full} OpenFWI corpus and submitted to the Kaggle “Geophysical Waveform Inversion’’ leaderboard.


\subsection{Hyperparameters and Training}

All models were trained on a single GPU (provided on DSMLP) with mixed‐precision (\texttt{torch.cuda.amp}) and the same 70 / 20 / 10 train-val-test split described earlier. Core hyper-parameters were selected with a 40–trial Optuna Bayesian search per model, using validation MAE as the objective.  Table~\ref{tab:hparams} summarizes the final settings.

\begin{table}
    \centering
    \footnotesize
    \renewcommand\arraystretch{1.05}
    \newcolumntype{Y}{>{\raggedright\arraybackslash}X}
    \begin{tabularx}{\linewidth}{@{}l c c c c c Y@{}}
    \toprule
    \textbf{Model} & \textbf{Opt.} & \textbf{LR} & \textbf{B} & \textbf{Ep.} & \textbf{Loss} & \textbf{Scheduler / key architectural settings} \\
    \midrule
    Fourier DeepONet      & Adam & $1\!\times\!10^{-3}$ & 4  & 100 & $\ell_1$ &
    \makecell[l]{width 64,\; modes $20\!\times\!20$} \\
    
    InversionNet          & Adam & $1\!\times\!10^{-3}$ & 8  & 100 & $\ell_1$ &
    --- \\
    
    VelocityGAN (G)       & Adam & $2\!\times\!10^{-4}$ & 8  & 50  & $\text{BCE}+\lambda\ell_1$ &
    $\lambda\!=\!100,\;\beta=(0.5,0.999)$ \\
    
    VelocityGAN (D)       & Adam & $2\!\times\!10^{-4}$ & 8  & 50  & BCE &
    $\beta=(0.5,0.999)$ \\
    
    Residual UNet         & Adam & $1\!\times\!10^{-3}$ & 8  & 100 & $\ell_1$ &
    depth 5,\; init‐feat 32 \\
    
    2-D FNO               & Adam & $5\!\times\!10^{-3}$ & 4  & 250 & $\ell_1$ &
    StepLR$\,(\!\times0.5\!/\!75$ep), modes $32\!\times\!32$, width 64, layers 4 \\
    
    Neural ODE (MLP)      & Adam & $1\!\times\!10^{-3}$ & 8  & 50  & $\ell_1$ &
    StepLR$\,(\!\times0.5\!/\!10$ep), tol $10^{-3}$, max 100 steps \\
    
    Aug.\ ODE (MLP)       & Adam & $1\!\times\!10^{-3}$ & 8  & 50  & $\ell_1$ &
    as above,\; aug.\ dim 1 \\
    
    Aug.\ ODE (CNN)       & Adam & $1\!\times\!10^{-3}$ & 8  & 50  & $\ell_1$ &
    CNN base,\; aug.\ dim 1 \\
    
    PCA\,+\,MLP           & Adam & $1.5\!\times\!10^{-1}$ & 16 & 100 & MSE &
    StepLR$\,(\!\times0.5\!/\!15$ep), hidden [2048,512,128], drop 0.05 \\
    \bottomrule
    \end{tabularx}
    \caption{Final hyper-parameters.  LR = learning rate, B = batch size, Ep. = epochs.}
    \label{tab:hparams}
\end{table}

\paragraph{Training protocol.}  

Gradients were left unclipped; weight decay was $10^{-4}$ for operator models and omitted elsewhere. Mini-batches were shuffled each epoch. During hyperparameter tuning, early stopping (15 epoch patience) selected the best checkpoint, which was then retrained from scratch using the final configuration. All test scores in Table~\ref{tab:quant} reflect these final retrained models.

\subsection{Quantitative Results and Ablation Studies}

We evaluate predicted velocity maps $\hat{v}$ against ground truth $v$ using four metrics: Mean Absolute Error (MAE), Root Mean Square Error (RMSE), Structural Similarity Index (SSIM), and relative $\ell_2$ error. MAE is the primary metric used in the Kaggle leaderboard. All scores are computed on the test split, with MAE on the full dataset reported for the best model. See Appendix~\ref{appendix:metrics-table} for definitions. Table \ref{tab:quant} reports validation MAE (used for early stopping) and four
test-set metrics for all nine models.  Lower is better except for SSIM, where
higher indicates greater structural fidelity.

\begin{table}
\centering
\small
\renewcommand{\arraystretch}{1.15}
\setlength{\tabcolsep}{5pt}
\begin{tabular}{@{}lccccc@{}}
\toprule
\textbf{Model} & \textbf{Val.\ MAE} $\downarrow$ & \textbf{Test MAE} $\downarrow$ & \textbf{RMSE} $\downarrow$ & \textbf{SSIM} $\uparrow$ & \textbf{Rel.\ $L_2$} $\downarrow$ \\
\midrule
Fourier DeepONet                & 59.5 & \textbf{71.4} & \textbf{76.3} & \textbf{0.916} & \textbf{0.029} \\
VelocityGAN                     & \textbf{52.3} & 72.4 & 114.7 & 0.904 & 0.044 \\
InversionNet                    & 68.1 & 82.5 & 135.6 & 0.634 & 0.052 \\
Residual UNet                   & 68.4 & 72.4 & 146.4 & 0.903 & 0.049 \\
Fourier Neural Operator (2-D)   & 124.2 & 106.9 & 166.7 & 0.727 & 0.056 \\
Neural ODE (MLP)                & 468.2 & 471.5 & 595.0 & 0.879 & 0.199 \\
Aug.\ Neural ODE (MLP)          & 468.0 & 471.4 & 595.2 & 0.876 & 0.199 \\
Aug.\ Neural ODE (CNN)          & 468.0 & 471.4 & 595.2 & 0.876 & 0.199 \\
PCA\,+\,MLP                     & 311.8 & 308.0 & 430.0 & 0.707 & 0.151 \\
\bottomrule
\end{tabular}
\caption{Performance on the held-out test split (\(N\!=\!200\)).
Best value in each column is \textbf{bold}.}
\label{tab:quant}
\end{table}

Since the 2D FNO and Neural ODE models initially did not perform as well as the state-of-the-art models (e.g.\ Fourier DeepONet, InversionNet), we performed hyper-parameter sweeps to identify the best configurations for these models. The results of these ablations are summarized in Figure~\ref{tab:ablation_studies}.


\vspace{-4pt}
\begin{figure}
\centering
\small
\setlength{\tabcolsep}{3pt}
\renewcommand{\arraystretch}{1.05}

\begin{minipage}[t]{0.48\linewidth}
\captionof{table}{2-D FNO ablations (bold = final choice).}
\label{tab:fno_ablate}
\begin{tabularx}{\linewidth}{@{}l X@{}}
\toprule
\textbf{Parameter} & \textbf{Explored values and observations}\\
\midrule
\# spectral blocks & 2: coarse details \hfill 5: heavy over-fit \\
                   & \textbf{4}: best MAE, mild over-fit \\[2pt]

Width & 16, 32: under-fit \\
      & \textbf{64}: better MAE, tolerable run-time \\[2pt]

Fourier modes & 4–16: jagged maps \\
              & \textbf{32}: captures fine structure \\
              & 64: GPU OOM / worse generalization \\[2pt]

Epochs & 10: under-train \hfill 200: modest gain \\
       & \textbf{250}: sweet-spot before over-fit \\[2pt]

Batch size & 4: slow \hfill \textbf{10}: stable / memory-safe \\
           & 20: occasional OOM, noisier loss \\
\bottomrule
\end{tabularx}
\end{minipage}\hfill
%
\begin{minipage}[t]{0.48\linewidth}
\captionof{table}{Neural-ODE ablations (MLP unless noted).}
\label{tab:ode_ablate}
\begin{tabularx}{\linewidth}{@{}l X@{}}
\toprule
\textbf{Parameter} & \textbf{Final choice and rationale}\\
\midrule
Hidden dimension & \textbf{64}; 128 slowed training, no MAE gain \\[2pt]

Learning rate & \textbf{$1\!\times\!10^{-3}$}; $1\!\times\!10^{-4}$ too slow, \\
              & $3\!\times\!10^{-4}$ used for CNN base \\[2pt]

Batch size & \textbf{8}; 32 caused GPU OOM \\[2pt]

Solver tol./steps & \textbf{$10^{-3}$ / 100}; faster convergence \\[2pt]

Augmented dim. & \textbf{1}; adds capacity with negligible cost \\[2pt]

Weight decay & \textbf{$5\!\times\!10^{-5}$} (CNN base only) \\
\bottomrule
\end{tabularx}
\end{minipage}

\vspace{-6pt}
\caption{Summary of hyper-parameter sweeps used to select the final configurations for two models: 2-D Fourier Neural Operator (FNO) and Neural ODE. The tables list the parameters explored, their values, and the observations that led to the final choices.}
\label{tab:ablation_studies}
\end{figure}

\subsection{Qualitative Results}

Figure \ref{fig:qualitative_results} shows qualitative results for the best-performing model (Fourier DeepONet) and the baseline InversionNet. The predicted velocity maps exhibit high structural fidelity, with the Fourier DeepONet capturing fine details and long-range correlations better than the other models.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{figures/qualitative_results.png}
    \caption{Qualitative comparison of predicted velocity maps from different models against the ground truth. Each row corresponds to a different sample in the testing set, with the first column showing the ground truth velocity map. The subsequent columns show the predictions from each model. The colorbar indicates the velocity scale in m/s. The Fourier DeepONet predictions closely match the ground truth, while other models exhibit varying degrees of deviation.}
    \label{fig:qualitative_results}
\end{figure}


\subsection{Discussion and Model Comparison}
Fourier DeepONet leads across all metrics, likely due to its spectral operator structure and multiscale skip connections. VelocityGAN achieves the lowest validation MAE but overfits slightly, while Residual UNet performs well on MAE yet has larger RMSE, suggesting it captures coarse structure but misses fine features. FNO lags in absolute error due to bandwidth constraints. Neural ODE variants and the PCA baseline perform worst, showing the need for spatial priors and expressive decoders.

\subsection{Kaggle Competition Submission}


\begin{figure}[t]
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/kaggle_rank.png}
        \caption{Public-leaderboard rank (591/6\,446).}
        \label{fig:kaggle_submission}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/fdonet_error_depth.png}
        \caption{MAE vs.\ depth.}
        \label{fig:fdonet_depth}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.32\linewidth}
        \centering
        \includegraphics[width=\linewidth]{figures/fdonet_error_velocity.png}
        \caption{MAE vs.\ velocity.}
        \label{fig:fdonet_vel}
    \end{subfigure}
    \vspace{-4pt}
    \caption{Fourier-DeepONet submission analysis on the hidden Kaggle test set. Figure (a) shows our current public leaderboard rank of 591 out of 6,446 participants. Figures (b) and (c) plot the mean absolute error (MAE) of our predictions against depth and velocity, respectively. This gives us insight into how well the model generalizes across different geological scenarios.}
    \label{fig:kaggle_triptych}
\end{figure}

To scale to the full 622\,GB dataset, we trained Fourier DeepONet using \texttt{torchrun} on 2×2080 GPUs with per-GPU batch size 4, FP16, DDP, and AdamW (lr=$3\times10^{-4}$, weight decay $10^{-4}$, EMA with $\alpha{=}0.999$). Early stopping triggered after 15 epochs. Training converged in 80 epochs (~18 GPU-hrs). The resulting model achieved an MAE of 195.5\,m/s on the hidden Kaggle test set. The gap with our in-house validation (71.4\,m/s) suggests domain shift, especially at greater depths and velocities (Figure~\ref{fig:kaggle_triptych}b–c), motivating future work in adaptation.

\section{Conclusion}
% \instructions{Conclusion [5\%]: Summarize your project and findings. High-level discussion about what you have learned from this project, what works, and what does not work, and ideas/suggestions for future work if you/others want to work on this problem.} 

\paragraph{Summary and Key Insights}
This project investigated a variety of data-driven models for seismic-to-velocity inversion. We implemented baseline architectures (InversionNet, VelocityGAN, Residual UNet), advanced neural operators (Fourier DeepONet, FNO), and a PCA-MLP dimensionality reduction pipeline. Among these, the Fourier DeepONet achieved the lowest test error on the Kaggle competition set when trained on the full OpenFWI dataset. Architectures that preserved spatial structure and captured long-range correlations consistently outperformed simpler MLP-based models.

\paragraph{What Worked and What Did Not}
Convolutional and operator-based models like UNet, DeepONet, and FNO were the most effective, as they leveraged spatial continuity and hierarchical features. Lightweight models like PCA-MLP were fast but less accurate due to loss of spatial information. Training on the reduced Kaggle subset led to frequent overfitting, indicating the need for larger-scale data or better regularization.

\paragraph{Future Directions}
Future work can focus on three areas:
\begin{itemize}[leftmargin=*, itemsep=1pt, topsep=2pt]
    \item \textbf{Noise Robustness:} Evaluate model stability under input perturbations to simulate real-world sensor noise, following findings in \cite{fdonet}.
    \item \textbf{Full-Scale Training:} Extend training of all models to the full OpenFWI dataset. Currently, only the Fourier DeepONet has been fully scaled.
    \item \textbf{Dimensionality Reduction with Stronger Backbones:} Replace the MLP in PCA-MLP with spatially-aware architectures like CNNs or Residual UNet to improve performance while retaining the benefits of dimensionality reduction.
\end{itemize}

% \begin{figure}[H]
%     \centering
%     \includegraphics[width=0.8\linewidth]{figures/conclusion1.png}
%     \caption{Proposed PCA-CNN architecture combining dimensionality reduction with a convolutional backbone.}
%     \label{fig:conclusion1}
% \end{figure}

\newpage
% \instructions{The following sections do not count towards the 8-Page Limits.}
\section*{Appendix}
\subsection*{GitHub Link}
% \instructions{Github Link [10\%]. Include a Link to your Project Github with your project codes with necessary documentation. Please include a top-level README.md file in your github repo. This top-level README should explain the layout of this repository and instructions such that users can run your code. Ensure your code can run and reproduce the results you presented in the report. Note that it is your responsibility to ensure that the code repo is working and the README.md is clear to follow.}

The link to our GitHub repository is as follows: \url{https://github.com/Girish-Krishnan/ECE-228-Final-Project/tree/main}. 

This repo contains all the code used to run our models, including the data preprocessing, model training, and evaluation scripts. The \texttt{README.md} file provides detailed instructions on how to set up the environment, install dependencies, and run the code to reproduce our results.


\subsection*{Team Member Contribution}
% \instructions{Describing each team member's contribution for this project (e.g., conceptualization, Data curation, Methodology, Software/Experiments, Report Writing, Poster preparation, etc)} 
Table \ref{tab:team_contrib} summarizes the contributions of each team member to the project. The goal was to have each team member implement at least 1-2 different model architectures so that we have several different models to compare against each other. The team members were also responsible for writing the report and poster sections that corresponded to their model implementations.

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.4}
    \setlist[itemize]{leftmargin=1.5em, topsep=2pt, itemsep=1pt}
    \begin{tabular}{p{3.5cm} p{11cm}}
        \toprule
        \textbf{Member} & \textbf{Key Contributions} \\
        \midrule

        \textbf{Harini Gurusankar} &
        \begin{itemize}
            \item Designed the baseline \emph{Neural ODE} and \emph{Augmented Neural ODE} models.
            \item Implemented MLP and CNN-based ODE variants in PyTorch.
            \item Wrote the methodology subsection and results discussion for ODE models.
            \item Contributed methodology content to the poster and presented it.
        \end{itemize} \\

        \textbf{Girish Krishnan} &
        \begin{itemize}
            \item Coordinated the project and designed the experimental pipeline.
            \item Implemented \emph{Fourier DeepONet}, residual \emph{UNet}, \emph{InversionNet}, and \emph{VelocityGAN}.
            \item Trained and submitted full-data DeepONet (best MAE: 59.5 m/s).
            \item Created metric visualizations (bar charts, heatmaps, radar plots).
            \item Wrote the abstract and results sections.
            \item Designed and presented the results section of the poster.
        \end{itemize} \\

        \textbf{Ryan Irwandy} &
        \begin{itemize}
            \item Developed the PCA-based baseline and accompanying MLP model.
            \item Wrote PCA utilities and normalization scripts.
            \item Ran experiments on component counts and dropout strategies.
            \item Wrote parts of the related work and methodology sections.
            \item Created and presented the poster’s introduction and PCA baseline sections.
        \end{itemize} \\

        \textbf{Yash Puneet} &
        \begin{itemize}
            \item Implemented the 2-D \emph{Fourier Neural Operator} with spectral blocks.
            \item Tuned mode counts and channel widths via hyperparameter sweeps.
            \item Created architecture figures for the FNO section.
            \item Wrote FNO-related work, methodology, and future work sections.
            \item Designed and presented the related work and future work sections of the poster.
        \end{itemize} \\

        \bottomrule
    \end{tabular}
    \caption{Summary of individual contributions to the project.}
    \label{tab:team_contrib}
\end{table}


\subsection*{Confirmation of Teaching Evaluation Submission (Bonus Points)}

Our team confirms that we have submitted our teaching evaluation for the ECE 228 course and the teaching assistant evaluations. Here are screenshots that confirm our submission (Figure \ref{fig:teaching_evaluation}).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{figures/teaching_evaluations/instructor_eval.png}
    \includegraphics[width=0.7\linewidth]{figures/teaching_evaluations/ta_eval.png}
    \includegraphics[width=0.9\linewidth]{figures/teaching_evaluations/set_eval.png}
    \caption{Teaching Evaluation Submission Confirmation}
    \label{fig:teaching_evaluation}
\end{figure}

Thanks for teaching us this awesome course!

\subsection*{Evaluation Metrics Formulae}
\label{appendix:metrics-table}

Table \ref{tab:metrics} summarizes the evaluation metrics used to quantify model performance on velocity map prediction.

\begin{table}
    \centering
    \renewcommand{\arraystretch}{1.4}
    \begin{tabular}{@{}p{1cm} p{8cm} c@{}}
    \toprule
    \textbf{Metric} & \textbf{Description} & \textbf{Formula} \\
    \midrule
    MAE & Measures average absolute difference between predicted and ground truth values. Also the primary metric used in the Kaggle competition. & 
    $\displaystyle \frac{1}{N} \sum_{i=1}^{N} |y_i - \hat{y}_i|$ \\
    \addlinespace
    RMSE & Penalizes large errors more than MAE; helpful for evaluating overall accuracy. &
    $\displaystyle \sqrt{ \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2 }$ \\
    \addlinespace
    SSIM & Captures perceptual similarity by comparing luminance, contrast, and structure. Useful for assessing structural fidelity. &
    $\displaystyle \frac{(2\mu_x \mu_y + C_1)(2\sigma_{xy} + C_2)}{(\mu_x^2 + \mu_y^2 + C_1)(\sigma_x^2 + \sigma_y^2 + C_2)}$ \\
    \addlinespace
    Relative $\ell_2$ Error & Measures the relative difference scaled by the ground truth magnitude. Provides a normalized global error measure. &
    $\displaystyle \frac{ \| y - \hat{y} \|_2 }{ \| y \|_2 }$ \\
    \bottomrule
    \vspace{0.1em}
    \end{tabular}
    \caption{Evaluation metrics used to quantify model performance on velocity map prediction. In the SSIM formula, $\mu_x$ and $\mu_y$ denote the local means of the predicted and ground truth images respectively, $\sigma_x^2$ and $\sigma_y^2$ are their local variances, $\sigma_{xy}$ is the local covariance, and $C_1$, $C_2$ are small constants that stabilize the division to avoid numerical instability.}
    \label{tab:metrics}
\end{table}

\bibliography{bib}
\bibliographystyle{abbrvnat}

\end{document}
